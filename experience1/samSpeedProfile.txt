Timer unit: 1e-06 s

Total time: 273.924 s
File: /home/tim/projects/sam/sam/imageutils.py
Function: split at line 68

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    68                                               @profile
    69                                               def split(self, first_dim, second_dim, third_dim, local_dir,
    70                                                         filename_prefix, hdfs_dir=None, copy_to_hdfs=False):
    71                                           
    72                                                   """Naive split method. Splits the 3d-image into shapes of given dimensions.
    73                                           
    74                                                   Keyword arguments:
    75                                                   first_dim, second_dim, third_dim: the desired first, second and third
    76                                                                                     dimensions of the splits,
    77                                                                                     respectively.
    78                                                   local_dir                       : the path to the local directory in
    79                                                                                     which the images will be saved
    80                                                   filename_prefix                 : the filename prefix
    81                                                   hdfs_dir                        : the hdfs directory name should the
    82                                                                                     image be copied to hdfs. If none is
    83                                                                                     provided and copy_to_hdfs is set to
    84                                                                                     True, the images will be copied to
    85                                                                                     the HDFSUtils class' default folder
    86                                                   copy_to_hdfs                    : boolean value indicating if the split
    87                                                                                     images should be copied to HDFS.
    88                                                                                     Default is False.
    89                                           
    90                                                   """
    91         2          2.0      1.0      0.0          try:
    92         2          2.0      1.0      0.0              if self.proxy is None:
    93                                                           raise AttributeError("Cannot split an image that has not yet"
    94                                                                                "been created.")
    95                                                   except AttributeError as aerr:
    96                                                       print('AttributeError: ', aerr)
    97                                                       sys.exit(1)
    98                                           
    99         2         18.0      9.0      0.0          num_x_iters = int(ceil(self.proxy.dataobj.shape[2] / third_dim))
   100         2          4.0      2.0      0.0          num_z_iters = int(ceil(self.proxy.dataobj.shape[1] / second_dim))
   101         2          3.0      1.5      0.0          num_y_iters = int(ceil(self.proxy.dataobj.shape[0] / first_dim))
   102                                           
   103         2          4.0      2.0      0.0          remainder_x = self.proxy.dataobj.shape[2] % third_dim
   104         2          3.0      1.5      0.0          remainder_z = self.proxy.dataobj.shape[1] % second_dim
   105         2          3.0      1.5      0.0          remainder_y = self.proxy.dataobj.shape[0] % first_dim
   106                                           
   107         2          2.0      1.0      0.0          is_rem_x = is_rem_y = is_rem_z = False
   108                                           
   109         6         21.0      3.5      0.0          for x in range(0, num_x_iters):
   110                                           
   111         4          4.0      1.0      0.0              if x == num_x_iters - 1 and remainder_x != 0:
   112                                                           third_dim = remainder_x
   113                                                           is_rem_x = True
   114                                           
   115        12         17.0      1.4      0.0              for z in range(0, num_z_iters):
   116                                           
   117         8         10.0      1.2      0.0                  if z == num_z_iters - 1 and remainder_z != 0:
   118                                                               second_dim = remainder_z
   119                                                               is_rem_z = True
   120                                           
   121        24         40.0      1.7      0.0                  for y in range(0, num_y_iters):
   122                                           
   123        16         16.0      1.0      0.0                      if y == num_y_iters - 1 and remainder_y != 0:
   124                                                                   first_dim = remainder_y
   125                                                                   is_rem_y = True
   126                                           
   127        16         23.0      1.4      0.0                      x_start = x * third_dim
   128        16         16.0      1.0      0.0                      x_end = (x + 1) * third_dim
   129                                           
   130        16         17.0      1.1      0.0                      z_start = z * second_dim
   131        16         14.0      0.9      0.0                      z_end = (z + 1) * second_dim
   132                                           
   133        16         14.0      0.9      0.0                      y_start = y * first_dim
   134        16         15.0      0.9      0.0                      y_end = (y + 1) * first_dim
   135                                           
   136        16         59.0      3.7      0.0                      split_array = self.proxy.dataobj[y_start:y_end,
   137        16         16.0      1.0      0.0                                                       z_start:z_end,
   138        16   95394676.0 5962167.2     34.8                                                       x_start:x_end]
   139        16     849579.0  53098.7      0.3                      split_image = nib.Nifti1Image(split_array, self.affine)
   140                                           
   141        16         89.0      5.6      0.0                      imagepath = None
   142                                           
   143                                                               # TODO: fix this so that position saved in image and not
   144                                                               # in filename
   145                                                               # if the remaining number of voxels does not match the
   146                                                               # requested number of voxels, save the image with the given
   147                                                               # filename prefix and the suffix:
   148                                                               # _<x starting coordinate>_<y starting coordinate>_
   149                                                               # <z starting coordinate>__rem-<x lenght>-<y-length>-
   150                                                               # <z length>
   151        16         19.0      1.2      0.0                      if is_rem_x or is_rem_y or is_rem_z:
   152                                           
   153                                                                   y_length = y_end - y_start
   154                                                                   z_length = z_end - z_start
   155                                                                   x_length = x_end - x_start
   156                                           
   157                                                                   imagepath = ('{0}/'
   158                                                                                '{1}_{2}_{3}_{4}__rem-{5}-{6}-{7}'
   159                                                                                '.nii.gz').format(local_dir,
   160                                                                                                  filename_prefix,
   161                                                                                                  y_start,
   162                                                                                                  z_start,
   163                                                                                                  x_start,
   164                                                                                                  y_length,
   165                                                                                                  z_length,
   166                                                                                                  x_length)
   167                                                               else:
   168        16         35.0      2.2      0.0                          imagepath = ('{0}/'
   169                                                                                '{1}_{2}_{3}_{4}'
   170        16         17.0      1.1      0.0                                       '.nii.gz').format(local_dir,
   171        16         15.0      0.9      0.0                                                         filename_prefix,
   172        16         14.0      0.9      0.0                                                         y_start,
   173        16         11.0      0.7      0.0                                                         z_start,
   174        16        147.0      9.2      0.0                                                         x_start)
   175                                           
   176        16  177677215.0 11104825.9     64.9                      nib.save(split_image, imagepath)
   177                                           
   178        16         35.0      2.2      0.0                      if copy_to_hdfs:
   179                                                                   self.utils.copy_to_hdfs(imagepath, ovrwrt=True,
   180                                                                                           save_path_to_file=True)
   181                                                               else:
   182        16         69.0      4.3      0.0                          legend_path = '{0}/legend.txt'.format(local_dir)
   183        16       1379.0     86.2      0.0                          with open(legend_path, 'a+') as im_legend:
   184        16        400.0     25.0      0.0                              im_legend.write('{0}\n'.format(imagepath))
   185                                           
   186        16         18.0      1.1      0.0                      is_rem_z = False
   187                                           
   188         4          4.0      1.0      0.0              is_rem_y = False

Total time: 136.944 s
File: /home/tim/projects/sam/sam/imageutils.py
Function: split_clustered_writes at line 327

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   327                                               @profile
   328                                               def split_clustered_writes(self, Y_splits, Z_splits, X_splits, out_dir,
   329                                                                          mem, filename_prefix="bigbrain",
   330                                                                          extension="nii", nThreads=1, hdfs_client=None):
   331                                                   """Clustered writes strategy. Split the input image into several splits, all share with the same
   332                                                   shape.
   333                                           
   334                                                   For now only supports Nifti1 images
   335                                           
   336                                                   :param Y_splits: How many splits in Y-axis
   337                                                   :param Z_splits: How many splits in Z-axis
   338                                                   :param X_splits: How many splits in X-axis
   339                                                   :param out_dir: Output Splits dir
   340                                                   :param mem: memory load each round
   341                                                   :param filename_prefix: each split's prefix filename
   342                                                   :param extension: extension of each split
   343                                                   :param nThreads: number of threads to trigger in each writing process
   344                                                   :param hdfs_client: hdfs client
   345                                                   :return:
   346                                                   """
   347                                           
   348         2          4.0      2.0      0.0          total_read_time = 0
   349         2          3.0      1.5      0.0          total_write_time = 0
   350         2          3.0      1.5      0.0          total_seek_time = 0
   351         2          4.0      2.0      0.0          total_seek_number = 0
   352                                           
   353                                                   # calculate remainder based on the original image file
   354         2         60.0     30.0      0.0          Y_size, Z_size, X_size = self.header.get_data_shape()
   355         2         19.0      9.5      0.0          bytes_per_voxel = self.header['bitpix'] / 8
   356         2          3.0      1.5      0.0          original_img_voxels = X_size * Y_size * Z_size
   357                                           
   358         2          3.0      1.5      0.0          if (X_size % X_splits != 0
   359         2          3.0      1.5      0.0                  or Z_size % Z_splits != 0
   360         2          3.0      1.5      0.0                  or Y_size % Y_splits != 0):
   361                                                       raise Exception("There is remainder after splitting, please reset "
   362                                                                       "the y,z,x splits")
   363                                           
   364         2          5.0      2.5      0.0          x_size = int(X_size / X_splits)
   365         2          3.0      1.5      0.0          z_size = int(Z_size / Z_splits)
   366         2          4.0      2.0      0.0          y_size = int(Y_size / Y_splits)
   367                                           
   368                                                   # get all split_names and write them to the legend file
   369         2          4.0      2.0      0.0          split_names = generate_splits_name(y_size, z_size, x_size, Y_size,
   370         2          4.0      2.0      0.0                                             Z_size, X_size, out_dir,
   371         2         87.0     43.5      0.0                                             filename_prefix, extension)
   372         2          4.0      2.0      0.0          legend_file = generate_legend_file(split_names, "legend.txt", out_dir,
   373         2       1176.0    588.0      0.0                                             hdfs_client=hdfs_client)
   374                                           
   375                                                   # in order to reduce overhead when reading headers of splits from hdfs,
   376                                                   # create a header cache in the local environment
   377         2          3.0      1.5      0.0          split_meta_cache = generate_headers_of_splits(split_names, y_size,
   378         2          2.0      1.0      0.0                                                        z_size, x_size,
   379         2         23.0     11.5      0.0                                                        self.header
   380                                                                                                 .get_data_dtype(),
   381         2      17751.0   8875.5      0.0                                                        hdfs_client=hdfs_client)
   382                                           
   383         2          5.0      2.5      0.0          start_index = end_index = 0
   384                                           
   385         2          3.0      1.5      0.0          mem = None if mem is not None and mem == 0 else mem
   386                                           
   387         2          2.0      1.0      0.0          num_splits = 0
   388         2          3.0      1.5      0.0          if mem is not None:
   389         2          8.0      4.0      0.0              num_splits = mem / (bytes_per_voxel * y_size * z_size * x_size)
   390                                                   else:
   391                                                       num_splits = 1
   392                                           
   393         2          4.0      2.0      0.0          if num_splits == 0:
   394                                                       print('ERROR: available memory is too low')
   395                                                       sys.exit(1)
   396                                           
   397         2          3.0      1.5      0.0          total_seek_number += len(split_names)
   398                                           
   399        10         21.0      2.1      0.0          while start_index < len(split_names):
   400         8        155.0     19.4      0.0              start_pos = pos_to_int_tuple(split_ext(split_names[start_index])
   401         8         66.0      8.2      0.0                                           [0].split('_'))
   402                                           
   403         8         47.0      5.9      0.0              end_index = start_index + num_splits - 1
   404                                           
   405         8         16.0      2.0      0.0              if end_index >= len(split_names):
   406                                                           end_index = len(split_names) - 1
   407                                           
   408         8         21.0      2.6      0.0              end_index =int(end_index)
   409         8         78.0      9.8      0.0              split_pos = pos_to_int_tuple(split_ext(split_names[end_index])
   410         8         31.0      3.9      0.0                                           [0].split('_'))
   411                                           
   412                                           
   413         8         12.0      1.5      0.0              end_pos = (split_pos[0] + y_size,
   414         8         16.0      2.0      0.0                         split_pos[1] + z_size,
   415         8         15.0      1.9      0.0                         split_pos[2] + x_size)
   416                                           
   417         8         17.0      2.1      0.0              split_pos_in_range = [pos_to_int_tuple(split_ext(x)[0].split('_'))
   418                                                                             for x
   419         8        200.0     25.0      0.0                                    in split_names[start_index:end_index + 1]]
   420                                           
   421         8         14.0      1.8      0.0              end_index, end_pos = adjust_end_read(split_names, start_pos,
   422         8         11.0      1.4      0.0                                                   split_pos, end_pos,
   423         8         11.0      1.4      0.0                                                   start_index, end_index,
   424         8         12.0      1.5      0.0                                                   split_pos_in_range, Y_size,
   425         8         20.0      2.5      0.0                                                   Z_size, split_meta_cache,
   426         8         48.0      6.0      0.0                                                   (y_size, z_size, x_size))
   427         8         15.0      1.9      0.0              print(("Reading from {0} at index {1} "
   428         8          9.0      1.1      0.0                     "--> {2} at index {3}").format(start_pos,
   429         8         10.0      1.2      0.0                                                    start_index,
   430         8         11.0      1.4      0.0                                                    end_pos,
   431         8        214.0     26.8      0.0                                                    end_index))
   432         8         15.0      1.9      0.0              extracted_shape = (end_pos[0] - start_pos[0],
   433         8         13.0      1.6      0.0                                 end_pos[1] - start_pos[1],
   434         8         13.0      1.6      0.0                                 end_pos[2] - start_pos[2])
   435                                           
   436         8         10.0      1.2      0.0              if extracted_shape[0] < Y_size:
   437                                                           total_seek_number += extracted_shape[1] * extracted_shape[2]
   438         8          9.0      1.1      0.0              elif extracted_shape[1] < Z_size:
   439         8         12.0      1.5      0.0                  total_seek_number += extracted_shape[2]
   440                                                       else:
   441                                                           total_seek_number += 1
   442                                           
   443         8         15.0      1.9      0.0              t = time()
   444         8     730336.0  91292.0      0.5              data = None
   445                                           
   446         8         50.0      6.2      0.0              if (end_pos[0] - start_pos[0] == Y_size
   447         8         17.0      2.1      0.0                      and end_pos[1] - start_pos[1] == Z_size):
   448                                                           data = self.proxy.dataobj[..., start_pos[2]:end_pos[2]]
   449                                                       else:
   450         8         69.0      8.6      0.0                  data = self.proxy.dataobj[start_pos[0]:end_pos[0],
   451         8         34.0      4.2      0.0                                            start_pos[1]:end_pos[1],
   452         8  107126173.0 13390771.6     78.2                                            start_pos[2]:end_pos[2]]
   453         8         41.0      5.1      0.0              total_read_time += time() - t
   454                                           
   455         8         16.0      2.0      0.0              one_round_split_metadata = {}
   456                                           
   457        24         59.0      2.5      0.0              for j in range(0, end_index - start_index + 1):
   458        16         27.0      1.7      0.0                  split_start = pos_to_int_tuple(split_ext(split_names
   459        16        245.0     15.3      0.0                                                           [start_index + j])
   460        16        107.0      6.7      0.0                                                 [0].split('_'))
   461        16         30.0      1.9      0.0                  split_start = (split_start[0] - start_pos[0],
   462        16         26.0      1.6      0.0                                 split_start[1] - start_pos[1],
   463        16         28.0      1.8      0.0                                 split_start[2] - start_pos[2])
   464        16         26.0      1.6      0.0                  y_e = split_start[0] + y_size
   465        16         22.0      1.4      0.0                  z_e = split_start[1] + z_size
   466        16         23.0      1.4      0.0                  x_e = split_start[2] + x_size
   467                                                           one_round_split_metadata[split_names[start_index + j]] = \
   468        16         23.0      1.4      0.0                      (split_start[0], y_e, split_start[1], z_e,
   469        16         33.0      2.1      0.0                       split_start[2], x_e)
   470                                           
   471         8         80.0     10.0      0.0              caches = _split_arr(one_round_split_metadata.items(), nThreads)
   472                                           
   473         8         12.0      1.5      0.0              st1 = time()
   474        24         59.0      2.5      0.0              for thread_round in caches:
   475        16         31.0      1.9      0.0                  tds = []
   476                                                           # one split's metadata triggers one thread
   477        32         79.0      2.5      0.0                  for i in thread_round:
   478        16        154.0      9.6      0.0                      ix = [int(x) for x in i[1]]
   479        16         96.0      6.0      0.0                      split_data = data[ix[0]: ix[1], ix[2]: ix[3], ix[4]: ix[5]]
   480        16         62.0      3.9      0.0                      td = threading.Thread(target=write_array_to_file,
   481        16         25.0      1.6      0.0                                            args=(split_data, i[0],
   482        16        950.0     59.4      0.0                                                  self.header_size, hdfs_client))
   483        16   24177272.0 1511079.5     17.7                      td.start()
   484        16         91.0      5.7      0.0                      tds.append(td)
   485        16         31.0      1.9      0.0                      del split_data
   486        32        226.0      7.1      0.0                  for t in tds:
   487        16    4887175.0 305448.4      3.6                      t.join()
   488         8         19.0      2.4      0.0              start_index = end_index + 1
   489                                           
   490         8         32.0      4.0      0.0              write_time = time() - st1
   491         8         27.0      3.4      0.0              total_write_time += write_time
   492         8        288.0     36.0      0.0              print("writing data takes ", write_time)
   493                                           
   494         2          4.0      2.0      0.0          return (total_read_time, total_write_time, total_seek_time,
   495         2          3.0      1.5      0.0                  total_seek_number)

Total time: 114.229 s
File: /home/tim/projects/sam/sam/imageutils.py
Function: split_multiple_writes at line 497

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   497                                               @profile
   498                                               def split_multiple_writes(self, Y_splits, Z_splits, X_splits, out_dir, mem,
   499                                                                         filename_prefix="bigbrain", extension="nii",
   500                                                                         hdfs_client=None, nThreads=1, benchmark=False):
   501                                                   """
   502                                                   Split the input image into several splits,
   503                                                   all share with the same shape
   504                                                   For now only support .nii extension
   505                                                   :param Y_splits: How many splits in Y-axis
   506                                                   :param Z_splits: How many splits in Z-axis
   507                                                   :param X_splits: How many splits in X-axis
   508                                                   :param out_dir: Output Splits dir
   509                                                   :param mem: memory load each round
   510                                                   :param filename_prefix: each split's prefix filename
   511                                                   :param extension: extension of each split
   512                                                   :param nThreads: number of threads to trigger in each writing process
   513                                                   :param hdfs_client: hdfs client
   514                                                   :return:
   515                                                   """
   516                                                   # calculate remainder based on the original image file
   517         2         45.0     22.5      0.0          Y_size, Z_size, X_size = self.header.get_data_shape()
   518         2         39.0     19.5      0.0          bytes_per_voxel = self.header['bitpix'] / 8
   519         2          4.0      2.0      0.0          original_img_voxels = X_size * Y_size * Z_size
   520                                           
   521         2          3.0      1.5      0.0          if (X_size % X_splits != 0
   522         2          3.0      1.5      0.0                  or Z_size % Z_splits != 0
   523         2          3.0      1.5      0.0                  or Y_size % Y_splits != 0):
   524                                                       raise Exception("There is remainder after splitting, "
   525                                                                       "please reset the y,z,x splits")
   526         2          4.0      2.0      0.0          x_size = X_size / X_splits
   527         2          2.0      1.0      0.0          z_size = Z_size / Z_splits
   528         2          2.0      1.0      0.0          y_size = Y_size / Y_splits
   529                                           
   530         2          3.0      1.5      0.0          if benchmark:
   531                                                       # for benchmarking
   532         2          2.0      1.0      0.0              total_read_time = 0
   533         2          2.0      1.0      0.0              total_seek_time = 0
   534         2          2.0      1.0      0.0              total_write_time = 0
   535         2          2.0      1.0      0.0              total_seek_number = 0
   536                                           
   537                                                   # get all split_names and write them to the legend file
   538         2          3.0      1.5      0.0          split_names = generate_splits_name(y_size, z_size, x_size, Y_size,
   539         2          3.0      1.5      0.0                                             Z_size, X_size, out_dir,
   540         2          2.0      1.0      0.0                                             filename_prefix,
   541         2        101.0     50.5      0.0                                             extension)
   542         2       1498.0    749.0      0.0          generate_legend_file(split_names, "legend.txt", out_dir, hdfs_client)
   543                                           
   544                                                   # generate all the headers for each split
   545                                                   # in order to reduce overhead when reading headers of splits from hdfs,
   546                                                   # create a header cache in the local environment
   547         2         43.0     21.5      0.0          print("create split meta data dictionary...")
   548         2          4.0      2.0      0.0          split_meta_cache = generate_headers_of_splits(split_names, y_size,
   549         2          2.0      1.0      0.0                                                        z_size, x_size,
   550         2         26.0     13.0      0.0                                                        self.header
   551                                                                                                     .get_data_dtype(),
   552         2      17084.0   8542.0      0.0                                                        hdfs_client)
   553                                           
   554         2         40.0     20.0      0.0          print("Get split indexes...")
   555         2          4.0      2.0      0.0          split_indexes = get_indexes_of_all_splits(split_names,
   556         2          3.0      1.5      0.0                                                    split_meta_cache,
   557         2   11427203.0 5713601.5     10.0                                                    Y_size, Z_size)
   558                                                   # drop the remainder which is less than one slice
   559                                                   # if mem is less than one slice, then set mem to one slice
   560                                                   mem = mem - mem % (Y_size * Z_size * bytes_per_voxel) \
   561         2        328.0    164.0      0.0              if mem >= Y_size * Z_size * bytes_per_voxel \
   562                                                       else Y_size * Z_size * bytes_per_voxel
   563                                           
   564                                                   # get how many voxels per round
   565         2          5.0      2.5      0.0          voxels = mem // bytes_per_voxel
   566         2         10.0      5.0      0.0          next_read_index = (0, voxels - 1)
   567                                           
   568                                                   # Core Loop:
   569         2          3.0      1.5      0.0          while True:
   570         6         21.0      3.5      0.0              next_read_offsets = (next_read_index[0] * bytes_per_voxel,
   571         6         29.0      4.8      0.0                                   next_read_index[1] * bytes_per_voxel + 1)
   572         6         14.0      2.3      0.0              st = time()
   573         6         11.0      1.8      0.0              print("From {} to {}".format(next_read_offsets[0],
   574         6        167.0     27.8      0.0                                           next_read_offsets[1]))
   575         6         10.0      1.7      0.0              from_x_index = index_to_voxel(next_read_index[0],
   576         6         39.0      6.5      0.0                                            Y_size, Z_size)[2]
   577         6         11.0      1.8      0.0              to_x_index = index_to_voxel(next_read_index[1] + 1,
   578         6         22.0      3.7      0.0                                          Y_size, Z_size)[2]
   579                                           
   580         6          8.0      1.3      0.0              st_read_time = time()
   581         6         46.0      7.7      0.0              print("start reading data to memory...")
   582         6   66969915.0 11161652.5     58.6              data_in_range = self.proxy.dataobj[..., int(from_x_index): int(to_x_index)]
   583                                           
   584         6         14.0      2.3      0.0              if benchmark:
   585         6         24.0      4.0      0.0                  end_time = time() - st_read_time
   586         6         11.0      1.8      0.0                  total_read_time += end_time
   587         6        194.0     32.3      0.0                  print("reading data takes ", end_time)
   588         6         11.0      1.8      0.0                  total_seek_number += 1
   589                                           
   590         6         10.0      1.7      0.0              one_round_split_metadata = {}
   591                                                       # create split metadata for all splits(position, write_range, etc.)
   592        54        121.0      2.2      0.0              for split_name in split_names:
   593        48    4641689.0  96701.9      4.1                  if check_in_range(next_read_index, split_indexes[split_name]):
   594        32         82.0      2.6      0.0                      split = split_meta_cache[split_name]
   595                                                               (X_index_min, X_index_max,
   596                                                                x_index_min, x_index_max) = \
   597        32         52.0      1.6      0.0                          extract_slices_range(split,
   598        32         47.0      1.5      0.0                                               next_read_index, Y_size,
   599        32      54521.0   1703.8      0.0                                               Z_size)
   600        32         63.0      2.0      0.0                      y_index_min = int(split.split_pos[-3])
   601        32         50.0      1.6      0.0                      z_index_min = int(split.split_pos[-2])
   602        32         46.0      1.4      0.0                      y_index_max = y_index_min + split.split_y
   603        32         45.0      1.4      0.0                      z_index_max = z_index_min + split.split_z
   604                                                               one_round_split_metadata[split_name] = \
   605        32         42.0      1.3      0.0                          (y_index_min, y_index_max, z_index_min, z_index_max,
   606        32         69.0      2.2      0.0                           X_index_min - from_x_index,
   607        32         80.0      2.5      0.0                           X_index_max - from_x_index + 1)
   608                                           
   609                                                       # Using multi-threading to send data to hdfs in parallel,
   610                                                       # which will parallelize writing process.
   611                                                       # nThreads: number of threads that are working on writing
   612                                                       # data at the same time.
   613                                           
   614         6        294.0     49.0      0.0              print("start {} threads to write data...".format(nThreads))
   615                                           
   616                                                       # separate all the splits' metadata to several pieces,
   617                                                       # each piece contains #nThreads splits' metadata.
   618         6         87.0     14.5      0.0              caches = _split_arr(one_round_split_metadata.items(), nThreads)
   619                                           
   620         6         19.0      3.2      0.0              st1 = time()
   621                                           
   622        38         81.0      2.1      0.0              for thread_round in caches:
   623        32         73.0      2.3      0.0                  tds = []
   624                                                           # one split's metadata triggers one thread
   625        64        153.0      2.4      0.0                  for i in thread_round:
   626        32         73.0      2.3      0.0                      ix = i[1]
   627        32        380.0     11.9      0.0                      ix = list(map(lambda x: int(x), ix))
   628        32         68.0      2.1      0.0                      data = data_in_range[ix[0]: ix[1],
   629        32         48.0      1.5      0.0                                           ix[2]: ix[3],
   630        32        222.0      6.9      0.0                                           ix[4]: ix[5]]
   631        32         90.0      2.8      0.0                      td = threading.Thread(target=write_array_to_file,
   632        32       1869.0     58.4      0.0                                            args=(data, i[0], 0, hdfs_client))
   633        32   25442927.0 795091.5     22.3                      td.start()
   634        32        153.0      4.8      0.0                      tds.append(td)
   635        32         64.0      2.0      0.0                      del data
   636        64        577.0      9.0      0.0                  for t in tds:
   637        32    5321746.0 166304.6      4.7                      t.join()
   638                                           
   639         6         21.0      3.5      0.0              write_time = time() - st1
   640         6        202.0     33.7      0.0              print("writing data takes ", write_time)
   641         6         10.0      1.7      0.0              if benchmark:
   642         6         11.0      1.8      0.0                  total_write_time += write_time
   643                                           
   644                                                       # clean
   645         6         15.0      2.5      0.0              del caches
   646         6         18.0      3.0      0.0              del one_round_split_metadata
   647                                           
   648         6         30.0      5.0      0.0              next_read_index = (next_read_index[1] + 1,
   649         6         20.0      3.3      0.0                                 next_read_index[1] + voxels)
   650                                                       #  last write, write no more than image size
   651         6         12.0      2.0      0.0              if next_read_index[1] >= original_img_voxels:
   652         4          7.0      1.8      0.0                  next_read_index = (next_read_index[0], original_img_voxels - 1)
   653                                                       # if write range is larger img size, we are done
   654         6         11.0      1.8      0.0              if next_read_index[0] >= original_img_voxels:
   655         2          2.0      1.0      0.0                  break
   656                                                       # clear
   657         4     345200.0  86300.0      0.3              del data_in_range
   658                                           
   659         4        226.0     56.5      0.0              print("one memory load takes ", time() - st)
   660                                           
   661         2          3.0      1.5      0.0          if benchmark:
   662         2          2.0      1.0      0.0              return (total_read_time, total_write_time, total_seek_time,
   663         2          4.0      2.0      0.0                      total_seek_number)

Total time: 499.097 s
File: /home/tim/projects/sam/sam/imageutils.py
Function: clustered_read at line 709

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   709                                               @profile
   710                                               def clustered_read(self, reconstructed, legend, mem,
   711                                                                  input_compressed, benchmark):
   712                                                   """ Clustered strategy but also Naive strategy and Buffered slice strategy if mem=0.
   713                                                   Reconstruct an image given a set of splits and amount of available
   714                                                   memory such that it can load subset of splits into memory for faster
   715                                                   processing.
   716                                           
   717                                                   Assumes all blocks are of the same dimensions.
   718                                           
   719                                                   Keyword arguments:
   720                                                   reconstructed          : the fileobject pointing to the to-be
   721                                                                            reconstructed image
   722                                                   legend                 : legend containing the URIs of the splits.
   723                                                                            Splits should be ordered in the way they
   724                                                                            should be written (i.e. along first dimension,
   725                                                                            then second, then third) for best performance
   726                                                   mem                    : Amount of available memory in bytes.
   727                                                                            If mem is None, it will only read one split at
   728                                                                            a time
   729                                                   NOTE: currently only supports nifti blocks as it uses 'bitpix' to
   730                                                         determine number of bytes per voxel. Element is specific
   731                                                         to nifti headers
   732                                                   """
   733                                           
   734         4        243.0     60.8      0.0          rec_dims = self.header.get_data_shape()
   735                                           
   736         4          4.0      1.0      0.0          y_size = rec_dims[0]
   737         4          3.0      0.8      0.0          z_size = rec_dims[1]
   738         4          2.0      0.5      0.0          x_size = rec_dims[2]
   739                                           
   740         4         39.0      9.8      0.0          bytes_per_voxel = self.header['bitpix'] / 8
   741                                           
   742         4     193044.0  48261.0      0.0          splits = sort_split_names(legend)
   743                                           
   744         4          5.0      1.2      0.0          total_read = 0
   745         4          1.0      0.2      0.0          total_assign = 0
   746         4          3.0      0.8      0.0          total_tobyte = 0
   747         4          2.0      0.5      0.0          total_seek = 0
   748         4          2.0      0.5      0.0          total_write = 0
   749         4          3.0      0.8      0.0          total_num_seeks = len(splits)
   750                                           
   751                                                   # if a mem is inputted as 0, proceed with naive implementation
   752                                                   # (same as not inputting a value for mem)
   753         4          4.0      1.0      0.0          mem = None if mem == 0 else mem
   754                                           
   755         4          1.0      0.2      0.0          remaining_mem = mem
   756         4          4.0      1.0      0.0          data_dict = {}
   757                                           
   758         4          1.0      0.2      0.0          unread_split = None
   759                                           
   760         4          4.0      1.0      0.0          start_index = 0
   761         4          1.0      0.2      0.0          end_index = 0
   762                                           
   763        28         60.0      2.1      0.0          while start_index < len(splits):
   764                                           
   765        24         22.0      0.9      0.0              if mem is not None:
   766         8         15.0      1.9      0.0                  end_index = self.get_end_index(data_dict, remaining_mem,
   767         8          5.0      0.6      0.0                                                 splits, start_index,
   768         8          4.0      0.5      0.0                                                 bytes_per_voxel, y_size,
   769         8      48975.0   6121.9      0.0                                                 z_size, x_size)
   770                                                       else:
   771        16         13.0      0.8      0.0                  end_index = start_index
   772        16         18.0      1.1      0.0                  print("Naive reading from split index "
   773        16        719.0     44.9      0.0                        "{0} -> {1}".format(start_index, end_index))
   774                                           
   775        24         41.0      1.7      0.0              read_time, assign_time = self.insert_elems(data_dict, splits,
   776        24         17.0      0.7      0.0                                                         start_index, end_index,
   777        24         16.0      0.7      0.0                                                         bytes_per_voxel,
   778        24         26.0      1.1      0.0                                                         y_size, z_size, x_size,
   779        24  351897860.0 14662410.8     70.5                                                         input_compressed)
   780                                           
   781        24        179.0      7.5      0.0              if not self.filepath.endswith('.gz'):
   782                                                           (seek_time, write_time, num_seeks) = \
   783        24         29.0      1.2      0.0                      write_dict_to_file(data_dict, reconstructed,
   784        24  146954604.0 6123108.5     29.4                                         bytes_per_voxel, self.header_size)
   785                                                       else:
   786                                                           (seek_time, write_time, num_seeks) = \
   787                                                               write_dict_to_gz_file(data_dict, reconstructed,
   788                                                                                  bytes_per_voxel, self.header_size)
   789                                           
   790        24        111.0      4.6      0.0              total_read += read_time
   791        24         20.0      0.8      0.0              total_assign += assign_time
   792        24         23.0      1.0      0.0              total_seek += seek_time
   793        24         16.0      0.7      0.0              total_num_seeks += num_seeks
   794        24         19.0      0.8      0.0              total_write += write_time
   795                                           
   796        24         18.0      0.8      0.0              remaining_mem = mem
   797                                           
   798        24         28.0      1.2      0.0              if start_index <= end_index:
   799        24         18.0      0.8      0.0                  start_index = end_index + 1
   800                                                       else:
   801                                                           break
   802                                           
   803         4        193.0     48.2      0.0          print("Total time spent reading: ", total_read)
   804         4         44.0     11.0      0.0          print("Total time spent seeking: ", total_seek)
   805         4         52.0     13.0      0.0          print("Total number of seeks: ", total_num_seeks)
   806         4         38.0      9.5      0.0          print("Total time spent writing: ", total_write)
   807                                           
   808         4          4.0      1.0      0.0          return total_read, total_write, total_seek, total_num_seeks

Total time: 251.994 s
File: /home/tim/projects/sam/sam/imageutils.py
Function: insert_elems at line 810

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   810                                               @profile
   811                                               def insert_elems(self, data_dict, splits, start_index, end_index,
   812                                                                bytes_per_voxel, y_size, z_size, x_size,
   813                                                                input_compressed):
   814                                                   """
   815                                                   Insert contiguous strips of image data into dictionary.
   816                                           
   817                                                   Keyword arguments:
   818                                           
   819                                                   data_dict       - empty dictionary to store key-value pairs
   820                                                                     representing seek position and value to be written,
   821                                                                     respectively
   822                                                   splits          - list of split filenames
   823                                                   start_index     - Start position in splits for instance of clustered
   824                                                                     read
   825                                                   end_index       - End position in splits for instance of clustered
   826                                                                     reads
   827                                                   bytes_per_voxel - Amount of bytes in a voxel in the reconstructed image
   828                                                   y_size          - first dimension's array size in reconstructed image
   829                                                   z_size          - second dimensions's array size in reconstructed image
   830                                                   x_size          - third dimensions's array size in reconstructed image
   831                                           
   832                                                   """
   833                                           
   834        24         22.0      0.9      0.0          write_type = None
   835        24      53660.0   2235.8      0.0          start_split = Split(splits[start_index].strip())
   836        24        122.0      5.1      0.0          start_pos = pos_to_int_tuple(start_split.split_pos)
   837                                           
   838        24      47418.0   1975.8      0.0          end_split = Split(splits[end_index].strip())
   839        24         92.0      3.8      0.0          split_pos = pos_to_int_tuple(end_split.split_pos)
   840        24         24.0      1.0      0.0          end_pos = (split_pos[0] + end_split.split_y,
   841        24         21.0      0.9      0.0                     split_pos[1] + end_split.split_z,
   842        24         18.0      0.8      0.0                     split_pos[2] + end_split.split_x)
   843                                           
   844        24         13.0      0.5      0.0          read_time = 0
   845        24         16.0      0.7      0.0          assign_time = 0
   846                                           
   847        56         85.0      1.5      0.0          for i in range(start_index, end_index + 1):
   848                                           
   849        32      61522.0   1922.6      0.0              split_im = Split(splits[i].strip())
   850        32        131.0      4.1      0.0              split_pos = pos_to_int_tuple(split_im.split_pos)
   851        32         21.0      0.7      0.0              idx_start = 0
   852                                           
   853        32         38.0      1.2      0.0              st = time()
   854        32   85256245.0 2664257.7     33.8              split_data = split_im.proxy.get_data()
   855        32         82.0      2.6      0.0              if input_compressed:
   856                                                           read_time += time() - st
   857                                           
   858                                                       # split is a complete slice
   859        32         49.0      1.5      0.0              if split_im.split_y == y_size and split_im.split_z == z_size:
   860                                                           t = time()
   861                                                           data = split_data.tobytes('F')
   862                                                           if not input_compressed:
   863                                                               read_time += time() - t
   864                                           
   865                                                           key = (split_pos[0] +
   866                                                                  split_pos[1] * y_size +
   867                                                                  split_pos[2] * y_size * z_size)
   868                                           
   869                                                           t = time()
   870                                                           data_dict[key] = data
   871                                                           assign_time += time() - t
   872                                           
   873                                                           # split is a complete row
   874                                           
   875                                                       # WARNING: Untested
   876        32         26.0      0.8      0.0              elif split_im.split_y == y_size and split_im.split_z < z_size:
   877                                                           for i in xrange(split_im.split_x):
   878                                                               t = time()
   879                                                               data = split_data[:, :, i].tobytes('F')
   880                                                               if not input_compressed:
   881                                                                   read_time += time() - t
   882                                           
   883                                                               key = (split_pos[0] +
   884                                                                      (split_pos[1] * y_size) +
   885                                                                      (split_pos[2] + i) * y_size * z_size)
   886                                           
   887                                                               t = time()
   888                                                               data_dict[key] = data
   889                                                               assign_time += time() - t
   890                                           
   891                                                       # split is an incomplete row
   892                                                       else:
   893     22432      14674.0      0.7      0.0                  for i in range(0, split_im.split_x):
   894  13574400    8500786.0      0.6      3.4                      for j in range(0, split_im.split_z):
   895  13552000    9156940.0      0.7      3.6                          t = time()
   896  13552000   77454527.0      5.7     30.7                          data = split_data[:, j, i].tobytes('F')
   897  13552000    9032919.0      0.7      3.6                          if not input_compressed:
   898  13552000   10599356.0      0.8      4.2                              read_time += time() - t
   899                                           
   900                                                                   key = (split_pos[0] +
   901  13552000   11010050.0      0.8      4.4                                 (split_pos[1] + j) * y_size +
   902  13552000   10747691.0      0.8      4.3                                 (split_pos[2] + i) * y_size * z_size)
   903                                           
   904  13552000    9297462.0      0.7      3.7                          t = time()
   905  13552000   10681026.0      0.8      4.2                          data_dict[key] = data
   906  13552000   10078817.0      0.7      4.0                          assign_time += time() - t
   907                                           
   908        24         21.0      0.9      0.0          return read_time, assign_time

Total time: 0.048459 s
File: /home/tim/projects/sam/sam/imageutils.py
Function: get_end_index at line 910

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   910                                               @profile
   911                                               def get_end_index(self, data_dict, remaining_mem, splits, start_idx,
   912                                                                 bytes_per_voxel, y_size, z_size, x_size):
   913                                                   """
   914                                                   Determine the clustered read's end index
   915                                           
   916                                                   Keyword arguments:
   917                                           
   918                                                   data_dict       - pre-initialized or empty (if naive) dictionary to
   919                                                                     store key-value pairs representing seek position and
   920                                                                     value to be written, respectively
   921                                                   remaining_mem   - remaining available memory in bytes
   922                                                   splits          - list of split filenames (sorted)
   923                                                   start_idx       - Start position in splits for instance of clustered
   924                                                                     read
   925                                                   bytes_per_voxel - number of bytes for a voxel in the reconstructed
   926                                                                     image
   927                                                   y_size          - first dimension of reconstructed image's array size
   928                                                   z_size          - second dimension of reconstructed image's array size
   929                                                   x_size          - third dimension of reconstructed image's array size
   930                                           
   931                                                   Returns: update end index of read
   932                                           
   933                                                   """
   934                                           
   935         8          9.0      1.1      0.0          split_meta_cache = {}
   936         8         18.0      2.2      0.0          split_name = splits[start_idx].strip()
   937                                           
   938         8      14504.0   1813.0     29.9          split_im = start_im = Split(split_name)
   939         8         50.0      6.2      0.1          split_pos = start_pos = pos_to_int_tuple(start_im.split_pos)
   940                                           
   941         8          6.0      0.8      0.0          split_meta_cache[split_name] = split_im
   942                                           
   943         8         17.0      2.1      0.0          remaining_mem -= start_im.split_bytes
   944                                           
   945         8          8.0      1.0      0.0          if remaining_mem < 0:
   946                                                       print("ERROR: insufficient memory provided")
   947                                                       sys.exit(1)
   948                                           
   949         8          5.0      0.6      0.0          split_positions = []
   950         8          6.0      0.8      0.0          split_positions.append(start_pos)
   951                                           
   952         8          4.0      0.5      0.0          end_idx = start_idx
   953                                           
   954        16         33.0      2.1      0.1          for i in range(start_idx + 1, len(splits)):
   955                                           
   956        14         13.0      0.9      0.0              split_name = splits[i].strip()
   957        14      23537.0   1681.2     48.6              split_im = Split(split_name)
   958        14         56.0      4.0      0.1              split_pos = pos_to_int_tuple(split_im.split_pos)
   959                                           
   960        14         10.0      0.7      0.0              split_meta_cache[split_name] = split_im
   961        14         16.0      1.1      0.0              remaining_mem -= split_im.split_bytes
   962                                           
   963        14         22.0      1.6      0.0              if remaining_mem >= 0:
   964         8          7.0      0.9      0.0                  split_positions.append(split_pos)
   965                                           
   966        14          8.0      0.6      0.0              end_idx = i
   967        14         11.0      0.8      0.0              if remaining_mem <= 0:
   968         6          4.0      0.7      0.0                  break
   969                                           
   970         8          4.0      0.5      0.0          if remaining_mem < 0:
   971         6          5.0      0.8      0.0              end_idx -= 1
   972         6          6.0      1.0      0.0              split_name = splits[end_idx].strip()
   973         6       9719.0   1619.8     20.1              split_im = Split(split_name)
   974         6         22.0      3.7      0.0              split_pos = pos_to_int_tuple(split_im.split_pos)
   975                                           
   976         8          8.0      1.0      0.0          end_pos = (split_pos[0] + split_im.split_y,
   977         8          5.0      0.6      0.0                     split_pos[1] + split_im.split_z,
   978         8          6.0      0.8      0.0                     split_pos[2] + split_im.split_x)
   979                                           
   980         8          6.0      0.8      0.0          end_idx, end_pos = adjust_end_read(splits, start_pos, split_pos,
   981         8          5.0      0.6      0.0                                             end_pos, start_idx, end_idx,
   982         8          4.0      0.5      0.0                                             split_positions, y_size, z_size,
   983         8         35.0      4.4      0.1                                             split_meta_cache)
   984         8         10.0      1.2      0.0          print("Reading from position "
   985         8          3.0      0.4      0.0                "{0} (index {1}) -> {2} (index {3})".format(start_pos, start_idx,
   986         8        270.0     33.8      0.6                                                            end_pos, end_idx))
   987         8          7.0      0.9      0.0          return end_idx

Total time: 197.016 s
File: /home/tim/projects/sam/sam/imageutils.py
Function: multiple_reads at line 989

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   989                                               @profile
   990                                               def multiple_reads(self, reconstructed, legend, mem,
   991                                                                  input_compressed, benchmark):
   992                                                   """
   993                                                   Reconstruct an image given a set of splits and amount of available
   994                                                   memory.
   995                                           
   996                                                   multiple_reads: load splits servel times to read a complete slice
   997                                                   Currently it can work on random shape of splits and in unsorted order
   998                                           
   999                                                   :param reconstructed: the fileobject pointing to the to-be
  1000                                                                         reconstructed image
  1001                                                   :param legend: containing the URIs of the splits.
  1002                                                   :param mem: bytes to be written into the file
  1003                                                   """
  1004         2        150.0     75.0      0.0          Y_size, Z_size, X_size = self.header.get_data_shape()
  1005         2         21.0     10.5      0.0          bytes_per_voxel = self.header['bitpix'] / 8
  1006         2          2.0      1.0      0.0          header_offset = self.header.single_vox_offset
  1007         2          4.0      2.0      0.0          reconstructed_img_voxels = X_size * Y_size * Z_size
  1008                                           
  1009                                                   # for now always going to return benchmarks
  1010                                                   # if benchmark:
  1011         2          0.0      0.0      0.0          total_read_time = 0
  1012         2          2.0      1.0      0.0          total_seek_time = 0
  1013         2          2.0      1.0      0.0          total_write_time = 0
  1014         2          1.0      0.5      0.0          total_seek_number = 0
  1015                                           
  1016                                                   # get how many voxels per round
  1017         2          7.0      3.5      0.0          voxels = mem / bytes_per_voxel
  1018         2          4.0      2.0      0.0          next_write_index = (0, voxels - 1)
  1019                                           
  1020                                                   # read the headers of all the splits
  1021                                                   # to filter the splits out of the write range
  1022         2      74237.0  37118.5      0.0          sorted_split_name_list = sort_split_names(legend)
  1023         2          3.0      1.5      0.0          split_meta_cache = {}
  1024                                           
  1025        18         22.0      1.2      0.0          for s in sorted_split_name_list:
  1026        16      25408.0   1588.0      0.0              split_meta_cache[s] = Split(s)
  1027                                           
  1028         2          2.0      1.0      0.0          split_indexes = get_indexes_of_all_splits(sorted_split_name_list,
  1029         2          0.0      0.0      0.0                                                    split_meta_cache,
  1030         2   11629069.0 5814534.5      5.9                                                    Y_size, Z_size)
  1031                                           
  1032                                                   # Core loop
  1033         2          4.0      2.0      0.0          while True:
  1034                                           
  1035         6         38.0      6.3      0.0              next_write_offsets = (next_write_index[0] * bytes_per_voxel,
  1036         6         23.0      3.8      0.0                                    next_write_index[1] * bytes_per_voxel + 1)
  1037         6         14.0      2.3      0.0              print("**************From {} "
  1038         6          5.0      0.8      0.0                    "to {}*****************".format(next_write_offsets[0],
  1039         6        323.0     53.8      0.0                                                    next_write_offsets[1]))
  1040                                           
  1041         6         12.0      2.0      0.0              data_dict = {}
  1042         6          7.0      1.2      0.0              found_first_split_in_range = False
  1043                                           
  1044        46         73.0      1.6      0.0              for split_name in sorted_split_name_list:
  1045        42         49.0      1.2      0.0                  in_range = check_in_range(next_write_index,
  1046        42    3420325.0  81436.3      1.7                                            split_indexes[split_name])
  1047        42         75.0      1.8      0.0                  if in_range:
  1048                                           
  1049        32         27.0      0.8      0.0                      found_first_split_in_range = True
  1050        32      61566.0   1923.9      0.0                      read_time_one_r = extract_rows(Split(split_name),
  1051        32         41.0      1.3      0.0                                                     data_dict,
  1052        32         34.0      1.1      0.0                                                     split_indexes[split_name],
  1053        32         21.0      0.7      0.0                                                     next_write_index,
  1054        32  108036111.0 3376128.5     54.8                                                     input_compressed, benchmark)
  1055                                           
  1056        32        107.0      3.3      0.0                      if benchmark:
  1057                                                                   total_seek_number += 1
  1058                                                                   total_read_time += read_time_one_r
  1059                                           
  1060        10          9.0      0.9      0.0                  elif not found_first_split_in_range:
  1061         8          8.0      1.0      0.0                      continue
  1062                                                           else:
  1063                                                               # because splits are sorted
  1064         2          3.0      1.5      0.0                      break
  1065                                           
  1066                                                       # time to write to file
  1067         6         39.0      6.5      0.0              if not self.filepath.endswith('.gz'):
  1068                                                           (seek_time, write_time, seek_number) = \
  1069         6          6.0      1.0      0.0                      write_dict_to_file(data_dict, reconstructed,
  1070         6   73757610.0 12292935.0     37.4                                         bytes_per_voxel, header_offset)
  1071                                                       else:
  1072                                                           (seek_time, write_time, seek_number) = \
  1073                                                               write_dict_to_gz_file(data_dict, reconstructed,
  1074                                                                                  bytes_per_voxel, header_offset)
  1075                                           
  1076         6          7.0      1.2      0.0              if benchmark:
  1077                                                           total_seek_number += seek_number
  1078                                                           total_seek_time += seek_time
  1079                                                           total_write_time += write_time
  1080                                           
  1081         6         32.0      5.3      0.0              next_write_index = (next_write_index[1] + 1,
  1082         6         17.0      2.8      0.0                                  next_write_index[1] + voxels)
  1083                                           
  1084                                                       #  last write, write no more than image size
  1085         6         13.0      2.2      0.0              if next_write_index[1] >= reconstructed_img_voxels:
  1086         4          2.0      0.5      0.0                  next_write_index = (next_write_index[0],
  1087         4          4.0      1.0      0.0                                      reconstructed_img_voxels - 1)
  1088                                           
  1089                                                       # if write range is larger img size, we are done
  1090         6          6.0      1.0      0.0              if next_write_index[0] >= reconstructed_img_voxels:
  1091         2          2.0      1.0      0.0                  break
  1092                                           
  1093         4      10894.0   2723.5      0.0              del data_dict
  1094                                           
  1095         2          1.0      0.5      0.0          if benchmark:
  1096                                                       print(total_read_time, total_write_time,
  1097                                                             total_seek_time, total_seek_number)
  1098                                                       return (total_read_time, total_write_time,
  1099                                                               total_seek_time, total_seek_number)
  1100                                                   else:
  1101         2          1.0      0.5      0.0              return (total_read_time, total_write_time,
  1102         2          2.0      1.0      0.0                      total_seek_time, total_seek_number)

Total time: 0.131746 s
File: /home/tim/projects/sam/sam/imageutils.py
Function: load_image at line 1104

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
  1104                                               @profile
  1105                                               def load_image(self, filepath, in_hdfs=None):
  1106                                           
  1107                                                   """Load image into nibabel
  1108                                                   Keyword arguments:
  1109                                                   filepath            : The absolute, relative path,
  1110                                                                         or HDFS URL of the image
  1111                                                                         **Note: If in_hdfs parameter is not set and file
  1112                                                                                 is located in HDFS, it is necessary that
  1113                                                                                 the path provided is an HDFS URL or an
  1114                                                                                 absolute/relative path with the
  1115                                                                                 '_HDFSUTILS_FLAG_' flag as prefix, or
  1116                                                                                 else it will conclude that file is
  1117                                                                                 located in local filesystem.
  1118                                                   in_hdfs             : boolean variable indicating if image is located
  1119                                                                         in HDFS or local filesystem. By default is
  1120                                                                         set to None. If not set (i.e. None), the function
  1121                                                                         will attempt to determine where the file is
  1122                                                                         located.
  1123                                                   """
  1124                                           
  1125        12         29.0      2.4      0.0          if self.utils is None:
  1126        12         15.0      1.2      0.0              in_hdfs = False
  1127                                                   elif in_hdfs is None:
  1128                                                       in_hdfs = self.utils.is_hdfs_uri(filepath)
  1129                                           
  1130        12          8.0      0.7      0.0          if in_hdfs:
  1131                                                       fh = None
  1132                                                       # gets hdfs path in the case an hdfs uri was provided
  1133                                                       filepath = self.utils.hdfs_path(filepath)
  1134                                           
  1135                                                       with self.utils.client.read(filepath) as reader:
  1136                                                           stream = reader.read()
  1137                                                           if self.is_gzipped(filepath, stream[:2]):
  1138                                                               fh = nib.FileHolder(
  1139                                                                       fileobj=GzipFile(fileobj=BytesIO(stream)))
  1140                                                           else:
  1141                                                               fh = nib.FileHolder(fileobj=BytesIO(stream))
  1142                                           
  1143                                                           if is_nifti(filepath):
  1144                                                               return nib.Nifti1Image.from_file_map({'header': fh,
  1145                                                                                                     'image': fh})
  1146                                                           if is_minc(filepath):
  1147                                                               return nib.Minc1Image.from_file_map({'header': fh,
  1148                                                                                                    'image': fh})
  1149                                                           else:
  1150                                                               print('ERROR: currently unsupported file-format')
  1151                                                               sys.exit(1)
  1152        12        560.0     46.7      0.4          elif not os.path.isfile(filepath):
  1153         6       1945.0    324.2      1.5              logging.warn("File does not exist in HDFS nor in Local FS. "
  1154                                                                    "Will only be able to reconstruct image...")
  1155         6          6.0      1.0      0.0              return None
  1156                                           
  1157                                                   # image is located in local filesystem
  1158         6          4.0      0.7      0.0          try:
  1159         6     129179.0  21529.8     98.1              return nib.load(filepath)
  1160                                                   except Exception as e:
  1161                                                       print("ERROR: Unable to load image into nibabel (verify that the file does not already exist but is broken)")
  1162                                                       sys.exit(1)

Total time: 0 s
File: /home/tim/projects/sam/sam/imageutils.py
Function: write_array_to_file at line 1533

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
  1533                                           @profile
  1534                                           def write_array_to_file(data_array, to_file, write_offset, hdfs_client=None):
  1535                                               """
  1536                                               :param data_array: consists of consistent data that to bo written to the
  1537                                                                  file
  1538                                               :param to_file: file path
  1539                                               :param reconstructed: reconstructed image file to be written
  1540                                               :param write_offset: file offset to be written
  1541                                               :param hdfs_client: HDFS client
  1542                                               :return: benchmarking params
  1543                                               """
  1544                                               write_time = 0
  1545                                               seek_time = 0
  1546                                               seek_number = 0
  1547                                               data = data_array.tobytes('F')
  1548                                               if hdfs_client is None:
  1549                                                   seek_start = time()
  1550                                                   fd=os.open(to_file, os.O_RDWR | os.O_APPEND)
  1551                                                   seek_number += 1
  1552                                                   write_start = time()
  1553                                                   os.pwrite(fd, data, write_offset)
  1554                                                       #f.flush()
  1555                                                       #os.fsync(f)
  1556                                                   write_time += time() - write_start
  1557                                                   os.close(fd)
  1558                                               else:
  1559                                                   write_start = time()
  1560                                                   with hdfs_client.write(to_file, append=True) as writer:
  1561                                                       writer.write(data)
  1562                                                   seek_number += 1
  1563                                                   write_time += time() - write_start
  1564                                           
  1565                                               del data_array
  1566                                               del data
  1567                                               return seek_time, write_time, seek_number

Total time: 148.349 s
File: /home/tim/projects/sam/sam/imageutils.py
Function: write_dict_to_file at line 1569

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
  1569                                           @profile
  1570                                           def write_dict_to_file(data_dict, to_file, bytes_per_voxel, header_offset):
  1571                                               """
  1572                                               :param data_array: consists of consistent data that to bo written to the
  1573                                                                  file
  1574                                               :param reconstructed: reconstructed image file to be written
  1575                                               :param write_offset: file offset to be written
  1576                                               :return: benchmarking params
  1577                                               """
  1578        30         26.0      0.9      0.0      seek_time = 0
  1579        30         12.0      0.4      0.0      write_time = 0
  1580        30          9.0      0.3      0.0      seek_number = 0
  1581                                           
  1582        30         13.0      0.4      0.0      no_seek = 0
  1583                                           
  1584  20328034   10356941.0      0.5      7.0      for k in sorted(data_dict.keys()):
  1585  20328004   21692358.0      1.1     14.6          seek_pos = int(header_offset + k * bytes_per_voxel)
  1586  20328004   10675119.0      0.5      7.2          data_bytes = data_dict[k]
  1587  20328004    9564835.0      0.5      6.4          write_start = time()
  1588  20328004   64895871.0      3.2     43.7          os.pwrite(to_file, data_bytes, seek_pos)
  1589  20328004   11543842.0      0.6      7.8          write_time += time() - write_start
  1590  20328004    9252117.0      0.5      6.2          del data_dict[k]
  1591  20328004   10367695.0      0.5      7.0          del data_bytes
  1592                                           
  1593        30        155.0      5.2      0.0      st = time()
  1594                                               #to_file.flush()
  1595                                               #os.fsync(to_file)
  1596        30         46.0      1.5      0.0      write_time += time() - st
  1597                                           
  1598        30         37.0      1.2      0.0      return seek_time, write_time, seek_number

